<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SINE">
  <meta name="keywords" content="Diffusion model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SINE: SINgle Image Editing with Text-to-Image Diffusion Models</title>

  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SINE: <u>SIN</u>gle Image <u>E</u>diting with Text-to-Image Diffusion Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://zhang-zx.github.io/">Zhixing Zhang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://phymhan.github.io/">Ligong Han</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://arnabgho.github.io/">Arnab Ghosh</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://people.cs.rutgers.edu/~dnm/">Dimitris Metaxas</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://alanspike.github.io/">Jian Ren</a><sup>2</sup>
            </span>
          </div>

          <h1 style="font-size:23px;font-weight:bold">Accepted to CVPR, 2023</h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Rutgers University,</span>
            <span class="author-block"><sup>2</sup>Snap Inc.</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2212.04489"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://github.com/zhang-zx/SINE"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://colab.research.google.com/github/zhang-zx/SINE/blob/master/SINE.ipynb"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-infinity"></i>
                  </span>
                  <span>Colab</span>
                </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser_v4.jpg">
      <h2 class="subtitle has-text-centered">
        Image manipulation on <i>one</i> real image.
      </h2>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent works on diffusion models have demonstrated a strong capability for conditioning image generation, 
            <i>e.g.</i>, text-guided image synthesis. Such success inspires many efforts trying to use large-scale pre-trained diffusion models for tackling a challenging problem--real image editing. 
            Works conducted in this area learn a unique textual token corresponding to several images containing the same object. 
            However, under many circumstances, only one image is available, such as the painting of the <i>Girl with a Pearl Earring</i>. 
            Using existing works on fine-tuning the pre-trained diffusion models with a single image causes severe overfitting issues. 
            The information leakage from the pre-trained diffusion models makes editing can not keep the same content as the given image while creating new features depicted by the language guidance. 
            This work aims to address the problem of single-image editing. 
            We propose a novel model-based guidance built upon the classifier-free guidance so that the knowledge from the model trained on a single image can be distilled into the pre-trained diffusion model, 
            enabling content creation even with one given image. 
            Additionally, we propose a patch-based fine-tuning that can effectively help the model generate images of arbitrary resolution. 
            We provide extensive experiments to validate the design choices of our approach and show promising editing capabilities, including changing style, content addition, and object manipulation.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Overview</h2>
    <div class="columns is-centered">
      

      <div class="column">
        <div class="content">
          <h2 class="title is-4">Fine-tuning Pipeline</h2>
          <img src="./static/images/overview_finetuning.png" >
        </div>
      </div>

      <div class="column">
        <div class="content">
          <h2 class="title is-4">Editing with Model-based Guidance</h2>
          <img src="./static/images/overview_editing.png" >
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Experiments</h2>

        <h3 class="title is-4">Editing on single source image from various domains.</h3>
        <div class="content has-text-justified">
          <p>
            We employ our method on various images and edit them with two target prompts at 512 × 512 resolution. 
            We show the wide range of edits our approach can be used, including but not limited to style transfer, content add-on, posture change, breed change, <i>etc</i>.
          </p>
          <img src="./static/images/editing.png">
        </div>

        <h3 class="title is-4">Arbitrary resolution editing.</h3>
        <div class="content has-text-justified">
          <p>
            Our method achieves higher-resolution image editing without artifacts like duplicates, even on ones that change the height-width ratio drastically.
          </p>
          <img src="./static/images/editing_resolution.png">
        </div>

        <h3 class="title is-4">In-the-wild human face manipulation.</h3>
        <div class="content has-text-justified">
          <p>
            We conduct various editing on human face photos, locally or globally. 
            The models are trained and edited at a resolution of 512 × 512.
          </p>
          <img src="./static/images/face_editing.png">
        </div>

        <h3 class="title is-4">More applications.</h3>
        <div class="content has-text-justified">
          <p>
            We show how our approach can be applied to various tasks in image editing, such as content removal (a), style generation (b), and style transfer (c).
          </p>
          <div class="columns is-centered">
      

            <div class="column">
              <div class="content">
                <h5 class="subtitle has-text-centered">
                  (a) Content Removal
                </h5>
                <img src="./static/images/content_removal.png" >
                
              </div>
            </div>
      
            <div class="column">
              <div class="content">
                <h5 class="subtitle has-text-centered">
                  (b) Style Generation
                </h5>
                <img src="./static/images/style_generation.png" >
                
              </div>
            </div>

            <div class="column">
              <div class="content">
                <h5 class="subtitle has-text-centered">
                  (c) Style Transfer
                </h5>
                <img src="./static/images/style_transfer.png" >
                
              </div>
            </div>
          </div>
        </div>


        <h3 class="title is-4">More results.</h3>
        <div class="content has-text-justified">
          <p>
            <b>A children’s painting of a castle.</b> 
            The generation resolution is set to H = 768 and W = 1024. We use K = 400 and v = 0.7 in this sample.
          </p>
          <img src="./static/images/high_res_castle_children.jpg">
        </div>
        <div class="content has-text-justified">
          <p>
            <b>A painting of a castle in the style of Claude Monet.</b> 
            The output resolution is set to H = 768 and W = 1024. We use K = 400 and v = 0.65 in this example.
          </p>
          <img src="./static/images/high_res_castle_monet.jpg">
        </div>
        <div class="content has-text-justified">
          <p>
            <b>A photo of a lake with many sailboats.</b> 
            The output resolution is set to H = 768 and W = 1024. We use K = 400 and v = 0.7 in this example.
          </p>
          <img src="./static/images/high_res_boat.jpg">
        </div>
        <div class="content has-text-justified">
          <p>
            <b>A desert. </b> 
            The output resolution is set to H = 768 and W = 1024. We use K = 500 and v = 0.8 in this example.
          </p>
          <img src="./static/images/high_res_desert1.jpg">
        </div>
        <div class="content has-text-justified">
          <p>
            <b>A desert. </b> 
            The output resolution is set to H = 768 and W = 1024. We use K = 500 and v = 0.8 in this example.
          </p>
          <img src="./static/images/high_res_desert.jpg">
        </div>
        <div class="content has-text-justified">
          <p>
            <b>A watercolor painting of a girl.</b> 
            The output resolution is set to H = 1024 and W = 768. We use K = 400 and v = 0.6 in this example.
          </p>
          <img src="./static/images/high_res_girl.jpg">
        </div>
      </div>
    </div>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
@article{zhang2022sine,
  title={SINE: SINgle Image Editing with Text-to-Image Diffusion Models},
  author={Zhang, Zhixing and Han, Ligong and Ghosh, Arnab and Metaxas, Dimitris and Ren, Jian},
  journal={arXiv preprint arXiv:2212.04489},
  year={2022}
}
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">

    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
